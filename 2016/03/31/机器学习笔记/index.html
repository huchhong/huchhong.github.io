<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习笔记 | Hong&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="最近在跟Coursera上斯坦福大学的机器学习课程，跟了几周课程了，强烈推荐这门课程，非常适合机器学习门外汉的入门学习。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记">
<meta property="og:url" content="http://huchhong.github.io/2016/03/31/机器学习笔记/index.html">
<meta property="og:site_name" content="Hong's blog">
<meta property="og:description" content="最近在跟Coursera上斯坦福大学的机器学习课程，跟了几周课程了，强烈推荐这门课程，非常适合机器学习门外汉的入门学习。">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_costfunciton.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_hypothesis.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_gradient.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/normal_equations.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/compare_gradient_normalequaiton.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_regression_hypothesis.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/sogmoid.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_regression1.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_cost_function.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic1.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic2.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/mapfeature.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/overfit_underfit.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/overfit_underfit2.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_costfunction_regulated.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient_regulated1.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient_regulated2.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic3.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic4.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/logistic5.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/one-vs-all.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/non-linear-classification.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/neural_network.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/feedforward_propagation.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/neural_network_costfunction.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/backpropagation.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/gz.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/gz2.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/neural_network_gradient.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/gradient_estimate.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/gradient_estimate2.PNG">
<meta property="og:image" content="http://7xowlb.com1.z0.glb.clouddn.com/random_init_param.PNG">
<meta property="og:updated_time" content="2016-04-01T10:51:13.379Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记">
<meta name="twitter:description" content="最近在跟Coursera上斯坦福大学的机器学习课程，跟了几周课程了，强烈推荐这门课程，非常适合机器学习门外汉的入门学习。">
  
    <link rel="alternative" href="/atom.xml" title="Hong&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://7xowlb.com1.z0.glb.clouddn.com/u=4074885463,3533660756&amp;fm=21&amp;gp=0.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Chaohong Hu</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="/#" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/C-C/" style="font-size: 20px;">C/C++</a> <a href="/tags/gcc/" style="font-size: 10px;">gcc</a> <a href="/tags/libvirt/" style="font-size: 10px;">libvirt</a> <a href="/tags/qemu/" style="font-size: 16.67px;">qemu</a> <a href="/tags/并发编程/" style="font-size: 10px;">并发编程</a> <a href="/tags/数据结构/" style="font-size: 13.33px;">数据结构</a> <a href="/tags/虚拟化/" style="font-size: 13.33px;">虚拟化</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">我是谁，我从哪里来，我到哪里去？我就是我，是颜色不一样的吃货…</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Chaohong Hu</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="http://7xowlb.com1.z0.glb.clouddn.com/u=4074885463,3533660756&amp;fm=21&amp;gp=0.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Chaohong Hu</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="/#" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-机器学习笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/03/31/机器学习笔记/" class="article-date">
  	<time datetime="2016-03-31T10:41:28.000Z" itemprop="datePublished">2016-03-31</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习笔记
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在跟Coursera上斯坦福大学的机器学习课程，跟了几周课程了，强烈推荐这门课程，非常适合机器学习门外汉的入门学习。</p>
<a id="more"></a>
<p>这篇笔记纯粹是为了记录学习到的各种算法的公式和使用，不涉及原理说明，算是为了巩固记忆的课程笔记吧。笔记里用到的图片和公式都是从课程视频以及练习中的指导pdf截取。</p>
<h2 id="第一周">第一周</h2><p>机器学习入门介绍，有一些重要的概念：</p>
<ul>
<li>监督学习<br>  回归问题和分类问题</li>
<li>未监督学习</li>
<li>代价函数<br>  衡量输出预测值和实际值之间的误差</li>
<li>梯度下降<br>  用于求代价函数关于模型参数的偏导数</li>
</ul>
<h2 id="第二周">第二周</h2><p>介绍多个变量的线性回归，开始有编程练习了。</p>
<h3 id="代价函数和梯度下降">代价函数和梯度下降</h3><p>线性回归使用的代价函数：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_costfunciton.PNG" alt="costfunction"><br>其中假设函数公式为:<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_hypothesis.PNG" alt="hypothesis"><br>参数的梯度下降更新公式为:<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/linear_regression_gradient.PNG" alt="gradient"><br>其中alpha为学习速率，alpha后的公式即为代价函数关于theta(j)的偏导。alpha值太低，收敛速度慢，而alpha太大，有可能导致不能收敛。对梯度下降来说，合适的学习速率需要逐一尝试，比如按0.3，0.1，0.03，0.01这样尝试。最好可以画出迭代次数和代价函数的关系图，以此判断收敛情况。</p>
<h3 id="特征的标准化">特征的标准化</h3><p>有时会发现有的特征值很大，比如在几百上千的数量级，有的特征值很小，在0.1的特征值。对线性回归来说，这会影响收敛速度，以此有这种情况，最好先将特征进行标准化，即将所有的特征都限定在相同的范围。</p>
<p>标准化也有不同的方式，一种方式是 xi = (xi - mean(x))/std(x)，其中mean(x)是x序列的均值，std(x)是标准差。另一种方式是xi = (xi - mean(x))/(max(x) - min(x))</p>
<h3 id="多项式回归">多项式回归</h3><p>线性回归也可以用于多项式回归，只需要将多项式项映射为线性回归项即可。比如使用房屋大小预测房屋价格时，发现可能假设函数更符合二次多项式，即h(size) = theta0 + theta1*size + theta2*size^2。这时可以将size映射为x1，size^2映射为x2就可以利用线性回归算法：h(x) = theta0 + theta1*x1 + theta2*x2。</p>
<h3 id="Normal_Equations">Normal Equations</h3><p>解决线性回归问题的时候，还可以利用矩阵直接求解使代价函数最小化的参数值。见下面例子：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/normal_equations.PNG" alt="normal equation"></p>
<p>梯度下降法和Normal Equations两种方法的比较见下图：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/compare_gradient_normalequaiton.PNG" alt="normal equation"><br>这里提到当训练集个数较小时更适合使用Normal Equations，较大时（超过10000）应该考虑使用梯度下降法。</p>
<h2 id="第三周">第三周</h2><p>介绍逻辑回归，名字虽然带有回归，可实际上是解决的是分类问题。</p>
<p>逻辑回归的思路是将特征空间一分为二(如果特征有两个，想象一条线将平面一分为二，如果特征有三个，想象一个平面将三维空间一分为二)，一边为正类，另一边为负类。逻辑回归解决的是二值分类问题，不过可以通过one-vs-all方法解决多分类（超过2类）的问题。</p>
<h3 id="假设函数，代价函数，梯度函数">假设函数，代价函数，梯度函数</h3><p>逻辑回归的假设函数是：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_regression_hypothesis.PNG" alt="hypothesis"><br>其中g(z)为S型函数:<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/sogmoid.PNG" alt="sigmoid"><br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_regression1.PNG" alt="slide1"><br>假设函数的值在[0,1]的范围。h(x)&gt;=0.5，目标分类 y=1, h(x)&lt;0.5, 目标分类y等于0。因此该假设函数可以理解为目标函数y等于1的概率，h(x)大于等于0.5意味着有较大概率为正分类。</p>
<p>代价函数为：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_cost_function.PNG" alt="cost_function"><br>梯度函数为：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient.PNG" alt="gradient"><br>此处梯度函数的公式形式恰好和线性回归里梯度函数的公式一样，只是假设函数不一样，因此实际上是不一样的。</p>
<h3 id="替代梯度下降的高级方法">替代梯度下降的高级方法</h3><p>这里一直用梯度下降来求解参数的最优解，这里介绍了另外的高级方法，比如Conjugate gradient，BFGS, L-BFGS。这些方法能够比梯度下降计算效率更高，更适用于大规模机器学习，比如特征很多的情况，而且也不需要手动指定学习速率。对这些方法，超出了这个课程的范畴，因此课程里提到了使用matlab/octave提供的函数黑盒来使用这些高级方法。不过这些方法同样需要用到代价函数和梯度函数来迭代求解最优解。</p>
<h3 id="多项式回归-1">多项式回归</h3><p>和线性回归一样，逻辑回归也可以将多项式变量映射为线性方程中的变量。使用多项式的原因是线性分类不能很好地符合训练数据。下图中，线性分类可以很好的对训练数据进行分类：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic1.PNG" alt="pic1"><br>但是，下面的情况就无能为力：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic2.PNG" alt="pic2"><br>使用多项式类可以在特征空间中划定一个复杂形状的边界，从而正确地将正类和负类分开。</p>
<p>使用多项式时需要进行特征映射，即指定多项式的最高幂次，然后将原来的输入映射为特征。比如原来有两个输入x1,x2,设定最高幂次为6，特征映射如下所示：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/mapfeature.PNG" alt=""><br>经过变换后，原来只是2个输入被映射为28维向量。由此也可以看出，当原先选择的特征数量较大时，使用多项式映射来获取较好的边界时，会导致最后的特征爆炸式增长，不利于计算，这在后面会有其他的机器学习方法解决。</p>
<p>当输入数量不是很大时，使用多项式映射的逻辑回归还是能够很好得完成分类任务。</p>
<h3 id="过拟合和欠拟合">过拟合和欠拟合</h3><p>先看线性回归中的情形，模型是使用房屋大小预测房价：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/overfit_underfit.PNG" alt="overfit_underfit"><br>再看逻辑回归中的情形：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/overfit_underfit2.PNG" alt="overfit_underfit"></p>
<p>可以看到，欠拟合由于模型太简单，不能很好的符合训练数据，而过拟合模型太复杂，虽然能够完美得符合训练数据，但是对测试数据也就是未出现在训练数据中的数据预测效果会较差，而合适的模型即能较好的符合训练数据，也保持了一定的鲁棒性。</p>
<h3 id="正则化代价函数和梯度函数">正则化代价函数和梯度函数</h3><p>为了解决过拟合和欠拟合问题，在代价函数和梯度函数中加入对模型复杂度的惩罚，通过引入额外的参数来对拟合程度进行折中。这种方法允许引入非常多的特征，最终通过参数的调整，可以得到合适的特征权重（theta）。</p>
<p>正则化后的代价函数：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_costfunction_regulated.PNG" alt="costfunction"><br>正则化后的梯度函数：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient_regulated1.PNG" alt="gradient1"><br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic_gradient_regulated2.PNG" alt="gradient2"><br>其中的lambda值越小，取得的参数越倾向于复杂的参数模型，造成过拟合，lambda越大，倾向于简单的模型，造成欠拟合。</p>
<p><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic3.PNG" alt="1"><br>lambda=1,合适的拟合<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic4.PNG" alt="2"><br>lambda=0，过拟合<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/logistic5.PNG" alt="3"><br>lambda=100，欠拟合</p>
<h3 id="多类的分类问题">多类的分类问题</h3><p>逻辑回归的模型一开始是用来解决二值分类的，但是应用one-vs-all方法，也可以用来解决多类的分类问题。假设一共有K个分类，对于每个类别，都分别应用一次逻辑回归，将当前类视为正类1，其他类统归负类0，一共得到K个模型，在预测的时候，对每个模型分别求出假设函数值。由于逻辑回归里假设函数值的意义为输出为正类的概率值，因此K个输出里，哪个假设函数值最高，就可以归入哪一类。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/one-vs-all.PNG" alt="one-vs-all"></p>
<h2 id="第四周">第四周</h2><p>这周介绍了神经网络。逻辑回归应用多项式特征虽然也可以表示非线性假设，但是当原始输入特征很多时，应用多项式假设容易造成特征空间急剧膨胀，这种情况逻辑回归不是很好的方法。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/non-linear-classification.PNG" alt="non-linear"></p>
<p>神经网络可以很好得应付这种非线性假设。我对神经网络的理解是每一层网络单独的看都是逻辑回归，而且使用的是线性模型。后面一层接着对上一层使用线性模型如此叠加之后，最后的输出就是对输入的复杂非线性模型，而且模型对应的参数个数要远小于逻辑回归在非线性假设时的爆炸式增长。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/neural_network.PNG" alt="neural network"></p>
<h3 id="前向传播和预测">前向传播和预测</h3><p>当给定模型参数theta时（参数的计算在第五周介绍），可以利用前向传播求出神经网络的输出层。由于神经网络的每一层都是逻辑回归，因此最终的输出值的意义仍然代表将输入对应的输出划分为该类的概率。因此对最终的分类，和逻辑回归一样，由假设函数的值决定分类结果。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/feedforward_propagation.PNG" alt="feedforward_propagation"></p>
<h2 id="第五周">第五周</h2><p>这周介绍神经网络模型的推导方法。</p>
<h3 id="代价函数和梯度函数">代价函数和梯度函数</h3><p>正则化后的代价函数如下：<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/neural_network_costfunction.PNG" alt="costfunction"><br>其中L表示层数，Sl表述第l层的节点个数。</p>
<h4 id="后向传播算法">后向传播算法</h4><p>后向传播算法用来计算代价函数关于模型参数的梯度函数。梯度函数的推导过程很复杂，课程里只是介绍了计算方法，正所谓一招在手，天下我有，工程应用知道计算方法也很不错了。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/backpropagation.PNG" alt="backpropagation"><br>其中需要计算g(z)的导数:<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/gz.PNG" alt="gz1"><br><img src="http://7xowlb.com1.z0.glb.clouddn.com/gz2.PNG" alt="gz2"><br><img src="http://7xowlb.com1.z0.glb.clouddn.com/neural_network_gradient.PNG" alt="gradient"></p>
<p>得到了代价函数和梯度函数的算法后，就可以应用梯度下降法或者其他更高级的方法求解出使代价函数最小的模型参数了。</p>
<h3 id="梯度检测">梯度检测</h3><p>鉴于神经网络的实现较为复杂，一个不小心脑子混乱实现出错，可能看到的还是经过多次迭代，代价函数逐渐减少，看着没有问题，但是得到的却是比正确实现时更差的预测精度，而你却浑然不觉。因此为了保证实现没有问题，课程在这个地方强烈推荐梯度检测。</p>
<p>之前后向传播里介绍了梯度函数的计算方法，但是还存在一种计算效率不高，但是实现非常简单的方法，非常适合用来检测后向传播的梯度计算方法是否正确实现了。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/gradient_estimate.PNG" alt="gradient_estimate"><br><img src="http://7xowlb.com1.z0.glb.clouddn.com/gradient_estimate2.PNG" alt="gradient_estimate"></p>
<p>检测的方法可以随意构建一个模型，指定神经网络的层数，每层的节点个数，输入，输出，模型参数值，然后分别使用这两种方法计算当前的梯度，查看结果是否相近。</p>
<h3 id="参数的初始值">参数的初始值</h3><p>在线性回归和逻辑回归里，参数的初始化都可以指定为从0开始（当然从其他值开始也可以）。但在神经网络里，参数初始化不能设置为全0，而应当全部采用随机值进行初始化，否则将导致中间隐藏层的节点是相等的特征，失去神经网路的意义。<br><img src="http://7xowlb.com1.z0.glb.clouddn.com/random_init_param.PNG" alt="random_init_param"></p>
<h2 id="第六周">第六周</h2><p>这一周提供一些应用机器学习的建议，毕竟之前已经学到手线性回归，逻辑回归，神经网络，实际应用的时候对于如何选择合适的模型，以及模型参数的设置还是有不少疑问。</p>
<h3 id="机器学习诊断">机器学习诊断</h3><p>假设当你使用正则化的线性回归对房价进行预测时，发现训练得出的模型用来预测房价的结果不是很理想，那么你下一步要做什么呢？以下是可选项：</p>
<ul>
<li>增加训练集个数</li>
<li>尝试缩小特征集</li>
<li>尝试增加特征</li>
<li>尝试增加特征集个数</li>
<li>尝试提高lambda值</li>
<li>尝试降低lambda值</li>
</ul>
<p>盲目的尝试以上方法很可能花费了大量时间却得不出想要的结果，因此这时候需要对当前的机器学习先进行诊断，以便知道怎样才能更好的提高机器学习的性能。</p>
<h4 id="评价过拟合和欠拟合">评价过拟合和欠拟合</h4>
      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2015/12/06/SkipList/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">SkipList</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>





<section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'huchh'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Chaohong Hu
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>